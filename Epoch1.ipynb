{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from csv import reader\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "def loader(data):\n",
    "    xvalues = []\n",
    "    yvalues = []\n",
    "    for row in data.data:\n",
    "        xvalues.append(row)\n",
    "    for row in data.target:\n",
    "        yvalues.append(row)\n",
    "    xlist = xvalues[:-50]\n",
    "    ylist = yvalues[:-50]\n",
    "    return xlist, ylist\n",
    "\n",
    "xlist, ylist = loader(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for row in xlist:\n",
    "    for num in row:\n",
    "        dataset.append(num)\n",
    "datasete = []\n",
    "newlist = []\n",
    "i=0\n",
    "new_list=[]\n",
    "while i<len(dataset):\n",
    "  datasete.append(dataset[i:i+4])\n",
    "  i+=4\n",
    "xlist = datasete\n",
    "xlist        \n",
    "for i in range(len(xlist)):\n",
    "    xlist[i].append(ylist[i])\n",
    "dataset = xlist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.1, 3.0, 4.6, 1.4, 1], [5.5, 2.4, 3.8, 1.1, 1], [5.4, 3.0, 4.5, 1.5, 1], [4.6, 3.2, 1.4, 0.2, 0], [5.7, 3.8, 1.7, 0.3, 0], [5.8, 2.6, 4.0, 1.2, 1], [6.0, 2.2, 4.0, 1.0, 1], [5.0, 2.3, 3.3, 1.0, 1], [4.7, 3.2, 1.3, 0.2, 0], [4.6, 3.1, 1.5, 0.2, 0], [4.6, 3.4, 1.4, 0.3, 0], [6.3, 2.5, 4.9, 1.5, 1], [5.2, 3.5, 1.5, 0.2, 0], [6.1, 2.8, 4.7, 1.2, 1], [5.1, 3.8, 1.9, 0.4, 0], [5.2, 4.1, 1.5, 0.1, 0], [6.0, 3.4, 4.5, 1.6, 1], [4.4, 3.0, 1.3, 0.2, 0], [5.7, 3.0, 4.2, 1.2, 1], [4.9, 3.6, 1.4, 0.1, 0], [5.6, 3.0, 4.5, 1.5, 1], [5.8, 2.7, 4.1, 1.0, 1], [5.1, 3.5, 1.4, 0.2, 0], [5.7, 4.4, 1.5, 0.4, 0], [5.9, 3.2, 4.8, 1.8, 1], [5.5, 2.5, 4.0, 1.3, 1], [6.7, 3.0, 5.0, 1.7, 1], [5.1, 3.5, 1.4, 0.3, 0], [5.8, 4.0, 1.2, 0.2, 0], [4.9, 3.0, 1.4, 0.2, 0], [5.7, 2.8, 4.5, 1.3, 1], [4.9, 3.1, 1.5, 0.2, 0], [4.7, 3.2, 1.6, 0.2, 0], [5.6, 3.0, 4.1, 1.3, 1], [6.6, 3.0, 4.4, 1.4, 1], [5.0, 3.2, 1.2, 0.2, 0], [5.4, 3.9, 1.3, 0.4, 0], [5.0, 3.3, 1.4, 0.2, 0], [6.6, 2.9, 4.6, 1.3, 1], [5.7, 2.6, 3.5, 1.0, 1], [5.9, 3.0, 4.2, 1.5, 1], [4.8, 3.1, 1.6, 0.2, 0], [4.8, 3.0, 1.4, 0.3, 0], [5.0, 3.5, 1.3, 0.3, 0], [5.7, 2.9, 4.2, 1.3, 1], [6.5, 2.8, 4.6, 1.5, 1], [4.3, 3.0, 1.1, 0.1, 0], [5.4, 3.4, 1.5, 0.4, 0], [5.1, 3.8, 1.6, 0.2, 0], [5.6, 2.9, 3.6, 1.3, 1], [6.4, 3.2, 4.5, 1.5, 1], [6.3, 3.3, 4.7, 1.6, 1], [6.4, 2.9, 4.3, 1.3, 1], [4.5, 2.3, 1.3, 0.3, 0], [5.3, 3.7, 1.5, 0.2, 0], [5.5, 2.6, 4.4, 1.2, 1], [5.1, 3.3, 1.7, 0.5, 0], [5.1, 3.7, 1.5, 0.4, 0], [4.4, 3.2, 1.3, 0.2, 0], [5.4, 3.4, 1.7, 0.2, 0], [5.5, 4.2, 1.4, 0.2, 0], [5.2, 2.7, 3.9, 1.4, 1], [5.6, 2.7, 4.2, 1.3, 1], [6.1, 2.8, 4.0, 1.3, 1], [6.2, 2.2, 4.5, 1.5, 1], [6.9, 3.1, 4.9, 1.5, 1], [5.5, 2.3, 4.0, 1.3, 1], [6.2, 2.9, 4.3, 1.3, 1], [4.6, 3.6, 1.0, 0.2, 0], [5.0, 3.0, 1.6, 0.2, 0], [5.1, 3.4, 1.5, 0.2, 0], [4.8, 3.4, 1.6, 0.2, 0], [4.8, 3.4, 1.9, 0.2, 0], [6.1, 2.9, 4.7, 1.4, 1], [5.1, 2.5, 3.0, 1.1, 1], [5.5, 2.4, 3.7, 1.0, 1], [6.0, 2.9, 4.5, 1.5, 1], [5.4, 3.7, 1.5, 0.2, 0], [5.2, 3.4, 1.4, 0.2, 0], [5.7, 2.8, 4.1, 1.3, 1]]\n"
     ]
    }
   ],
   "source": [
    "def split(dataset):\n",
    "    train_set = []\n",
    "    test_set = []\n",
    "    num = 0\n",
    "    for row in dataset:\n",
    "        while num < int(len(dataset)*0.8):\n",
    "            train_set.append(row)\n",
    "            num +=1\n",
    "            break\n",
    "        while num >= int(len(dataset)*0.8):\n",
    "            test_set.append(row)\n",
    "            num += 1\n",
    "            break\n",
    "    return train_set, test_set\n",
    "        \n",
    "train_set, test_set = split(dataset)   \n",
    "print(train_set)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  1.0\n",
      "Precision: 1.0\n",
      "Recall:    1.0\n",
      "F1 Score:  1.0\n"
     ]
    }
   ],
   "source": [
    "weights = np.zeros(len(train_set[0])-1)\n",
    "def predict(train, weights, lrn_r, epoch):\n",
    "    z = 0\n",
    "    ch_weights = []\n",
    "    n = 0\n",
    "    while n<epoch:\n",
    "        predictions = []\n",
    "        for row in train:\n",
    "            f = np.dot(weights, row[:-1])\n",
    "            yhat = 1.0 if f>z else 0.0\n",
    "            predictions.append(yhat)\n",
    "    ####Weights\n",
    "            for i in range(len(row[:-1])):\n",
    "                weights[i] += lrn_r*(row[-1]-yhat)*row[i]\n",
    "                ch_weights.append(weights[i])\n",
    "        n += 1\n",
    "    return predictions, ch_weights\n",
    "\n",
    "predictions, ch_weights = predict(train_set, weights, 0.1, 1000)\n",
    "len(ch_weights)\n",
    "predictions\n",
    "def accuracy(predicted, actual):\n",
    "    score = 0\n",
    "    for i in range(len(predicted)):\n",
    "        if predicted[i] == actual[i]:\n",
    "            score += 1\n",
    "    return f\"{score/len(actual)*100}%\"\n",
    "\n",
    "\n",
    "def test(test, weights):\n",
    "    tpred = []\n",
    "    tactual = [row[-1] for row in test]\n",
    "    for row in test_set:\n",
    "        pred = np.dot(row[:-1], weights) \n",
    "        tpred.append(0 if pred<0 else 1)\n",
    "        \n",
    "    return tpred, tactual\n",
    "\n",
    "\n",
    "tpred, tactual = test(test_set, weights)\n",
    "\n",
    "def evaluation(tpred, tacutal):\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    for i in range(len(tactual)):\n",
    "        if tpred[i] == tactual[i]:\n",
    "            if tpred[i] == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "        else:\n",
    "            if tpred[i] == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "    recall = tp/(tp+fn)\n",
    "    precision = tp/(tp+fp)\n",
    "    accuracy = (tp+tn)/(tp+tn+fn+fp)\n",
    "    f1 = 2*((precision*recall)/(precision+recall))\n",
    "    return print(f\"\"\"Accuracy:  {accuracy}\n",
    "Precision: {precision}\n",
    "Recall:    {recall}\n",
    "F1 Score:  {f1}\"\"\")\n",
    "\n",
    "\n",
    "evaluation(tpred, tactual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2 , -0.56,  0.76,  0.32])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Irena\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in Perceptron in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "# training the sklearn Perceptron\n",
    "clf = Perceptron(random_state=None, eta0=0.1, shuffle=False, fit_intercept=False)\n",
    "clf.fit([row[:-1] for row in train_set], [row[-1] for row in train_set])\n",
    "y_predict = clf.predict([row[:-1] for row in test_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2 , -0.56,  0.76,  0.32])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.2 , -0.56,  0.76,  0.32]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
